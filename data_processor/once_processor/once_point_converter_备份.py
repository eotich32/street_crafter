
#!/usr/bin/env python3
# once_point_converter.py â†’ é‡‡ç”¨ lidar2image åŒæ¬¾æŠ•å½±
import os
import cv2
import numpy as np
import pickle
import argparse
from tqdm import tqdm
import open3d as o3d

# ---------- å·¥å…· ----------
def load_bin(bin_path):
    pts = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4)
    return pts[:, :3]

def voxel_downsample_indices(xyz: np.ndarray,
                             voxel_size: float) -> np.ndarray:
    """
    çº¯ numpy å®ç°ï¼šå¯¹ NÃ—3 ç‚¹äº‘åšä½“ç´ é™é‡‡æ ·ï¼Œè¿”å›ä¿ç•™çš„åŸå§‹ç´¢å¼•ã€‚
    è§„åˆ™ï¼šæ¯ä¸ª voxel åªä¿ç•™ç¬¬ä¸€ä¸ªè½è¿›æ¥çš„ç‚¹ã€‚

    Parameters
    ----------
    xyz : np.ndarray, shape=(N, 3), dtype=float32/float64
        åŸå§‹ç‚¹äº‘åæ ‡
    voxel_size : float
        ä½“ç´ è¾¹é•¿

    Returns
    -------
    np.ndarray, shape=(M,), dtype=int64
        è¢«é€‰ä¸­çš„åŸå§‹ç‚¹ç´¢å¼•ï¼ŒM â‰¤ N
    """
    # 1. è®¡ç®—æ¯ä¸ªç‚¹çš„ voxel åæ ‡ï¼ˆæ•´æ•° keyï¼‰
    voxel_coord = np.floor(xyz / voxel_size).astype(np.int32)

    # 2. ç”¨å­—å…¸è®°å½•æ¯ä¸ª voxel ç¬¬ä¸€æ¬¡å‡ºç°çš„ç´¢å¼•
    voxel_dict = {}
    for i, vox in enumerate(voxel_coord):
        key = (vox[0], vox[1], vox[2])
        if key not in voxel_dict:   # åªä¿ç•™ç¬¬ä¸€ä¸ª
            voxel_dict[key] = i

    # 3. è¿”å›ç´¢å¼•æ•°ç»„
    return np.fromiter(voxel_dict.values(), dtype=np.int64)

# ---------- ç»Ÿä¸€å†…å‚è¯»å–ï¼ˆä¸ once_converter.py ä¿æŒä¸€è‡´ï¼‰ ----------
def read_intrinsic(cam_path: str):
    """
    cam_path: /xxx/xxx/intrinsics/{cam_id}.txt
    æ–‡ä»¶å†…å®¹: fx fy cx cy k1 k2 p1 p2 k3   ï¼ˆ9 ä¸ªæ•°ï¼‰
    è¿”å› K(3Ã—3), dist(5,)
    """
    vec = np.loadtxt(cam_path)
    if vec.ndim == 0:          # å•å…ƒç´ é€€åŒ–æˆ 0-d
        vec = vec.reshape(-1)
    if vec.size != 9:
        raise ValueError(
            f'å†…å‚æ ¼å¼é”™è¯¯ï¼æœŸæœ› 9 ä¸ªæ•° (fx fy cx cy k1 k2 p1 p2 k3)ï¼Œ'
            f'å®é™…å¾—åˆ° {vec.size} ä¸ªï¼š{vec}'
        )
    fx, fy, cx, cy, k1, k2, p1, p2, k3 = vec
    K = np.array([[fx, 0, cx],
                  [0, fy, cy],
                  [0,  0,  1]])
    dist = np.array([k1, k2, p1, p2, k3])
    return K, dist                    

def load_KRT(extr_path, intr_path):
    extr = np.loadtxt(extr_path).reshape(4, 4)   # lidar->cam
    K, dist = read_intrinsic(intr_path)          # K å·²ç»æ˜¯ 3Ã—3ï¼Œdist æ˜¯ 5
    return K, dist, extr

def load_pkl(pkl_path):
    with open(pkl_path, 'rb') as f:
        return pickle.load(f)
'''
def load_KRT(extr_path, intr_path):
    extr = np.loadtxt(extr_path).reshape(4, 4)   # lidar->cam
    intr = np.loadtxt(intr_path)
    K = intr[:3, :3]
    D = intr[3:] if intr.shape[0] >= 4 else np.zeros(5)
    return K, D, extr
'''
def bbox_to_corner3d(bbox):
    x, y, z, l, w, h, yaw = bbox
    cos, sin = np.cos(yaw), np.sin(yaw)
    corners = np.array([
        [-l/2, -w/2, -h/2], [ l/2, -w/2, -h/2],
        [ l/2,  w/2, -h/2], [-l/2,  w/2, -h/2],
        [-l/2, -w/2,  h/2], [ l/2, -w/2,  h/2],
        [ l/2,  w/2,  h/2], [-l/2,  w/2,  h/2],
    ])
    R = np.array([[cos, -sin, 0], [sin, cos, 0], [0, 0, 1]])
    return (R @ corners.T).T + np.array([x, y, z])

def inbbox_points(xyz, corners):
    mn = corners.min(0); mx = corners.max(0)
    return ((xyz >= mn) & (xyz <= mx)).all(1)

def store_ply(path, xyz, rgb,mask=None):
    N = xyz.shape[0]
    with open(path, 'w') as f:
        f.write("ply\nformat ascii 1.0\n")
        f.write(f"element vertex {N}\n")
        f.write("property float x\nproperty float y\nproperty float z\n")
        f.write("property uchar red\nproperty uchar green\nproperty uchar blue\n")
        if mask is not None:
            f.write("property uchar mask\n")
        f.write("end_header\n")
        for i in range(N):
            f.write(f"{xyz[i, 0]} {xyz[i, 1]} {xyz[i, 2]} "
                    f"{int(rgb[i, 0])} {int(rgb[i, 1])} {int(rgb[i, 2])}")
            if mask is not None:
                f.write(f" {int(mask[i])}")
            f.write("\n")
'''
def downsample_and_save(xyz, rgb, save_path):
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(xyz)
    pcd.colors = o3d.utility.Vector3dVector(rgb / 255.0)
    pcd = pcd.voxel_down_sample(voxel_size=0.15)
    pcd, _ = pcd.remove_radius_outlier(nb_points=10, radius=0.5)
    xyz_out = np.asarray(pcd.points).astype(np.float32)
    rgb_out = (np.asarray(pcd.colors) * 255).astype(np.uint8)
    store_ply(save_path, xyz_out, rgb_out)
'''
def downsample_and_save(xyz, rgb, save_path):
    import open3d as o3d
    from sklearn.neighbors import NearestNeighbors

    # â‘  åªæ‹¿ç´¢å¼•ï¼Œä¸æ”¹åæ ‡
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(xyz)
    pcd.colors = o3d.utility.Vector3dVector(rgb / 255.0)

    if hasattr(o3d.geometry.PointCloud, 'get_voxel_down_sample_indices'):
        idx = np.asarray(pcd.get_voxel_down_sample_indices())
    else:
        idx = voxel_downsample_indices(xyz, 0.15)

    xyz_out = xyz[idx]      # âœ ç”¨åŸå§‹åæ ‡
    rgb_out = rgb[idx]

    # â‘¡ åŠå¾„ç¦»ç¾¤
    neigh_idx = nn.radius_neighbors(xyz_out, return_distance=False)
    neighbors = np.array([len(idx) for idx in neigh_idx])
    keep = neighbors > 10
    xyz_out = xyz_out[keep]
    rgb_out = rgb_out[keep]

    # â‘¢ å†™ç›˜
    store_ply(save_path, xyz_out, rgb_out)

# ---------- æ–°å¢ï¼šlidar2image åŒæ¬¾æŠ•å½± ----------
IMAGE_SIZE = (1920, 1020)   # (W, H)

def project_lidar_to_image(pts, T_velo2cam, K, img_size=(1920, 1020)):
    pts_h = np.concatenate([pts, np.ones((pts.shape[0], 1))], 1)
    pts_cam = (T_velo2cam @ pts_h.T).T[:, :3]
    mask = pts_cam[:, 2] > 0
    pts_cam = pts_cam[mask]
    pts_2d = (K @ pts_cam.T).T
    pts_2d = pts_2d[:, :2] / pts_2d[:, 2:3]
    w, h = img_size
    inside = (pts_2d[:, 0] >= 0) & (pts_2d[:, 0] < w) & \
             (pts_2d[:, 1] >= 0) & (pts_2d[:, 1] < h)
    
    # è¿”å›åŸå§‹ç‚¹äº‘é•¿åº¦çš„æ©ç å’Œå¯¹åº”çš„ uv
    full_mask = np.zeros(pts.shape[0], dtype=bool)
    full_mask[mask] = inside
    uv_full = np.zeros((pts.shape[0], 2), dtype=int)
    uv_full[full_mask] = pts_2d[inside].astype(int)
    z_full = np.zeros(pts.shape[0], dtype=float)
    z_full[full_mask] = pts_cam[inside, 2]
    
    return uv_full, full_mask, z_full

# ---------- ä¸»æµç¨‹ ----------
# ---------- ä¸»æµç¨‹ï¼ˆå·²è¿‡æ»¤å•å¸§ actorï¼‰ ----------
'''
def process(seq_dir, seq_name, CAM_IDS):
    base = os.path.join(seq_dir, seq_name)
    for sub in ['images', 'lidar', 'ego_pose', 'extrinsics', 'intrinsics', 'track']:
        assert os.path.exists(os.path.join(base, sub)), f"Missing {sub}"

    img_dir      = os.path.join(base, 'images')
    lidar_in_dir = os.path.join(base, 'lidar')
    track_dir    = os.path.join(base, 'track')

    out_bg   = os.path.join(base, 'lidar', 'background'); os.makedirs(out_bg, exist_ok=True)
    out_actor= os.path.join(base, 'lidar', 'actor');      os.makedirs(out_actor, exist_ok=True)
    out_depth= os.path.join(base, 'lidar', 'depth');      os.makedirs(out_depth, exist_ok=True)

    track_info = load_pkl(os.path.join(track_dir, 'track_info.pkl'))
    track_info = {int(k): v for k, v in track_info.items()}

    bin_files = sorted([f for f in os.listdir(lidar_in_dir) if f.endswith('.bin')])
    frame_ids = [f.split('.')[0] for f in bin_files]

    KRT = {}
    for cam_id in CAM_IDS:
        K, D, extr = load_KRT(os.path.join(base, 'extrinsics', f'{cam_id}.txt'),
                              os.path.join(base, 'intrinsics', f'{cam_id}.txt'))
        KRT[cam_id] = {'K': K, 'D': D, 'extr': extr}

    bg_xyz_list, bg_rgb_list = [], []
    actor_dict = {}   # tid -> {'xyz': [], 'rgb': [], 'frame_list': []}  # ğŸ”§

    # ---------- å…ˆæ”¶é›†æ‰€æœ‰å¸§ ----------
    for frame_id in tqdm(frame_ids, desc=seq_name):
        xyz = load_bin(os.path.join(lidar_in_dir, f'{frame_id}.bin'))
        rgb = np.zeros_like(xyz, dtype=np.uint8)
        mask = np.zeros(xyz.shape[0], dtype=bool)

        for cam_id, calib in KRT.items():
            img_path = os.path.join(img_dir, f'{int(frame_id):06d}_{cam_id}.jpg')
            if not os.path.exists(img_path):
                continue
            img = cv2.imread(img_path)[..., ::-1]
            h, w = img.shape[:2]
            K, extr = calib['K'], calib['extr']

            uv, inlier, z = project_lidar_to_image(xyz, np.linalg.inv(extr), K, (w, h))
            if inlier.any():
                rgb[inlier] = img[uv[inlier, 1], uv[inlier, 0]]
                mask[inlier] = True

            # ---------- æ·±åº¦å›¾ ----------
            depth = np.ones((h, w), dtype=np.float32) * 1e5
            if len(uv) > 0:
                depth[uv[:, 1], uv[:, 0]] = np.minimum(depth[uv[:, 1], uv[:, 0]], z)
            depth[depth >= 1e5] = 0
            np.savez_compressed(os.path.join(out_depth, f'{int(frame_id):06d}_{cam_id}.npz'),
                                mask=depth > 0, value=depth[depth > 0])
            depth_vis = cv2.applyColorMap((np.clip(depth, 0, 80) / 80 * 255).astype(np.uint8),
                                          cv2.COLORMAP_PLASMA)
            depth_vis_img = img.copy()
            depth_vis_img[depth > 0] = depth_vis[depth > 0]
            cv2.imwrite(os.path.join(out_depth, f'{int(frame_id):06d}_{cam_id}.jpg'),
                        depth_vis_img[..., ::-1])

        # ---------- ä¿å­˜èƒŒæ™¯ ----------
        store_ply(os.path.join(out_bg, f'{int(frame_id):06d}.ply'), xyz, rgb, mask)
        bg_xyz_list.append(xyz)
        bg_rgb_list.append(rgb)

        # ---------- æŠ  actor ----------
        frame_idx = int(frame_id)
        if frame_idx in track_info:
            for tid, obj in track_info[frame_idx].items():
                bbox = np.array([obj['lidar_box'][k] for k in
                                 ['center_x', 'center_y', 'center_z',
                                  'length', 'width', 'height', 'heading']])
                corners = bbox_to_corner3d(bbox)
                mask_actor = inbbox_points(xyz, corners)
                if mask_actor.sum() == 0:
                    continue
                actor_sub = os.path.join(out_actor, str(tid))
                os.makedirs(actor_sub, exist_ok=True)
                store_ply(os.path.join(actor_sub, f'{int(frame_id):06d}.ply'),
                          xyz[mask_actor], rgb[mask_actor], mask_actor)
                # è®°å½•å¸§å·
                if tid not in actor_dict:
                    actor_dict[tid] = {'xyz': [], 'rgb': [], 'frame_list': []}
                actor_dict[tid]['xyz'].append(xyz[mask_actor])
                actor_dict[tid]['rgb'].append(rgb[mask_actor])
                actor_dict[tid]['frame_list'].append(frame_idx)

    # ---------- è¿‡æ»¤å•å¸§ actor ----------
    # åªä¿ç•™å‡ºç°å¤šå¸§çš„ track
    actor_dict = {tid: data for tid, data in actor_dict.items()
                  if len(set(data['frame_list'])) > 1}

    # ---------- è¾“å‡º full.ply ----------
    if bg_xyz_list:
        bg_xyz = np.concatenate(bg_xyz_list, axis=0)
        bg_rgb = np.concatenate(bg_rgb_list, axis=0)
        downsample_and_save(bg_xyz, bg_rgb, os.path.join(out_bg, 'full.ply'))
    for tid, data in actor_dict.items():
        xyz = np.concatenate(data['xyz'], axis=0)
        rgb = np.concatenate(data['rgb'], axis=0)
        downsample_and_save(xyz, rgb, os.path.join(out_actor, tid, 'full.ply'))
'''
# ---------- ä¸»æµç¨‹ï¼ˆä¸ waymo ä¿å­˜é€»è¾‘å¯¹é½ï¼‰ ----------
def process(seq_dir, seq_name, CAM_IDS):
    base = os.path.join(seq_dir, seq_name)
    for sub in ['images', 'lidar', 'ego_pose', 'extrinsics', 'intrinsics', 'track']:
        assert os.path.exists(os.path.join(base, sub)), f"Missing {sub}"

    img_dir      = os.path.join(base, 'images')
    lidar_in_dir = os.path.join(base, 'lidar')
    track_dir    = os.path.join(base, 'track')

    out_bg   = os.path.join(base, 'lidar', 'background'); os.makedirs(out_bg, exist_ok=True)
    out_actor= os.path.join(base, 'lidar', 'actor');      os.makedirs(out_actor, exist_ok=True)
    out_depth= os.path.join(base, 'lidar', 'depth');      os.makedirs(out_depth, exist_ok=True)

    #track_info = load_pkl(os.path.join(track_dir, 'track_info.pkl'))
    #track_info = {int(k): v for k, v in track_info.items()}
    track_info = load_pkl(os.path.join(track_dir, 'track_info.pkl'))
    track_info = {int(k): v for k, v in track_info.items()}
    # â†“â†“â†“ åŠ è½½ trajectory
    trajectory = load_pkl(os.path.join(track_dir, 'trajectory.pkl'))

    bin_files = sorted([f for f in os.listdir(lidar_in_dir) if f.endswith('.bin')])
    frame_ids = [f.split('.')[0] for f in bin_files]

    KRT = {}
    for cam_id in CAM_IDS:
        K, D, extr = load_KRT(os.path.join(base, 'extrinsics', f'{cam_id}.txt'),
                              os.path.join(base, 'intrinsics', f'{cam_id}.txt'))
        KRT[cam_id] = {'K': K, 'D': D, 'extr': extr}

    # åªç”¨æ¥åˆå¹¶ actor full.ply
    actor_dict = {}

    for frame_id in tqdm(frame_ids, desc=seq_name):
        xyz = load_bin(os.path.join(lidar_in_dir, f'{frame_id}.bin'))
        rgb = np.zeros_like(xyz, dtype=np.uint8)
        mask = np.zeros(xyz.shape[0], dtype=bool)

        # ---------- æŠ•å½±æŸ“è‰² ----------
        for cam_id, calib in KRT.items():
            img_path = os.path.join(img_dir, f'{int(frame_id):06d}_{cam_id}.jpg')
            if not os.path.exists(img_path):
                continue
            img = cv2.imread(img_path)[..., ::-1]
            h, w = img.shape[:2]
            K, extr = calib['K'], calib['extr']

            uv, inlier, z = project_lidar_to_image(xyz, np.linalg.inv(extr), K, (w, h))
            if inlier.any():
                rgb[inlier] = img[uv[inlier, 1], uv[inlier, 0]]
                mask[inlier] = True

            # æ·±åº¦å›¾ï¼ˆç•¥ï¼Œä¸ä½ åŸä»£ç ç›¸åŒï¼‰
            depth = np.ones((h, w), dtype=np.float32) * 1e5
            if len(uv) > 0:
                depth[uv[:, 1], uv[:, 0]] = np.minimum(depth[uv[:, 1], uv[:, 0]], z)
            depth[depth >= 1e5] = 0
            np.savez_compressed(os.path.join(out_depth, f'{int(frame_id):06d}_{cam_id}.npz'),
                                mask=depth > 0, value=depth[depth > 0])
            #depth_vis = cv2.applyColorMap((np.clip(depth, 0, 80) / 80 * 255).astype(np.uint8),
                                          #cv2.COLORMAP_PLASMA)
            depth_norm = np.clip(depth, 0, 80) / 80
            depth_uint8 = (depth_norm * 255).astype(np.uint8)
            depth_vis = cv2.applyColorMap(255 - depth_uint8, cv2.COLORMAP_JET) 
            
            depth_vis_img = img.copy()
            depth_vis_img[depth > 0] = depth_vis[depth > 0]
            cv2.imwrite(os.path.join(out_depth, f'{int(frame_id):06d}_{cam_id}.jpg'),
                        depth_vis_img[..., ::-1])

        # ---------- èƒŒæ™¯ï¼šå•å¸§ç›´æ¥å†™åŸå§‹åæ ‡ ----------
        store_ply(os.path.join(out_bg, f'{int(frame_id):06d}.ply'), xyz, rgb, mask)

        frame_idx = int(frame_id)
        if frame_idx in track_info:
            for tid, obj in track_info[frame_idx].items():
                bbox = np.array([obj['lidar_box'][k] for k in
                                ['center_x', 'center_y', 'center_z',
                                'length', 'width', 'height', 'heading']])
                corners = bbox_to_corner3d(bbox)
                #bbox[3:6] *= 1.2 
                inbbox_mask = inbbox_points(xyz, corners)   # ä¸–ç•Œç³»ä¸‹æŠ ç‚¹
                if inbbox_mask.sum() == 0:
                    continue
                actor_sub = os.path.join(out_actor, str(tid))
                os.makedirs(actor_sub, exist_ok=True)

                # â‘  ä¸–ç•Œ â†’ å±€éƒ¨æ¡†ï¼ˆä¸ full.ply ä¸€è‡´ï¼‰
                pose_v = trajectory[tid]['poses_vehicle'][trajectory[tid]['frames'].index(frame_idx)]
                xyz_w = xyz[inbbox_mask]
                xyz_h = np.concatenate([xyz_w, np.ones((xyz_w.shape[0], 1))], axis=1)
                xyz_l = (np.linalg.inv(pose_v) @ xyz_h.T).T[:, :3]
                rgb_l = rgb[inbbox_mask]
                mask_uint8 = inbbox_mask.astype(np.uint8) 

                # â‘¡ å†™å±€éƒ¨æ¡†åæ ‡
                store_ply(os.path.join(actor_sub, f'{int(frame_id):06d}.ply'), xyz_l, rgb_l,mask_uint8)

                # â‘¢ ç´¯ç§¯åˆ°åˆå¹¶æ± ï¼ˆä¹Ÿæ˜¯å±€éƒ¨æ¡†ï¼‰
                if tid not in actor_dict:
                    #actor_dict[tid] = {'xyz': [], 'rgb': []}
                    actor_dict[tid] = {'xyz': [], 'rgb': [], 'mask': []} 
                actor_dict[tid]['xyz'].append(xyz_l)
                actor_dict[tid]['rgb'].append(rgb_l)
                actor_dict[tid]['mask'].append(mask_uint8)

    # ---------- ä»…åˆå¹¶ actor full.plyï¼ˆä¸ waymo è„šæœ¬ä¸€è‡´ï¼‰ ----------
    '''
    import open3d as o3d
    from sklearn.neighbors import NearestNeighbors
    for tid, data in actor_dict.items():
        xyz_world_list = data['xyz']          # List[N,3] ä¸–ç•Œåæ ‡
        rgb_list       = data['rgb']
        pose_list      = [trajectory[tid]['poses_vehicle'][i]
                          for i in range(len(xyz_world_list))]  # å¯¹åº”å¸§çš„ pose

        # â‘  ä¸–ç•Œ â†’ å±€éƒ¨æ¡†ï¼ˆä¸ waymo ä¸€è‡´ï¼‰
        xyz_local_list = []
        rgb_local_list = []
        for xyz_w, rgb_f, pose_v in zip(xyz_world_list, rgb_list, pose_list):
            # pose_v: ä¸–ç•Œâ†’vehicleï¼Œå±€éƒ¨æ¡† = inv(pose_v)
            xyz_h = np.concatenate([xyz_w, np.ones((xyz_w.shape[0], 1))], axis=1)
            xyz_l = (np.linalg.inv(pose_v) @ xyz_h.T).T[:, :3]
            xyz_local_list.append(xyz_l)
            rgb_local_list.append(rgb_f)

        xyz_local = np.concatenate(xyz_local_list, axis=0)
        rgb_local = np.concatenate(rgb_local_list, axis=0)

        # â‘¡ å±€éƒ¨æ¡†ä¸‹åˆå¹¶ + é™é‡‡æ ·ï¼ˆç´¢å¼•æ³•ï¼‰
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(xyz_local)
        pcd.colors = o3d.utility.Vector3dVector(rgb_local / 255.0)
        pcd = pcd.voxel_down_sample(voxel_size=0.15)
        pcd, _ = pcd.remove_radius_outlier(nb_points=10, radius=0.5)

        # æ‹¿ç´¢å¼•å›åŸå§‹æ•°ç»„
        if hasattr(o3d.geometry.PointCloud, 'get_voxel_down_sample_indices'):
            idx = np.asarray(pcd.get_voxel_down_sample_indices())
        else:
            idx = voxel_downsample_indices(xyz_local, 0.15)
        xyz_out = xyz_local[idx]
        rgb_out = rgb_local[idx]

        store_ply(os.path.join(out_actor, tid, 'full.ply'), xyz_out, rgb_out)
    '''
    # ---------- ä»…åˆå¹¶ actor full.plyï¼ˆå±€éƒ¨æ¡†åæ ‡ï¼Œä¸å†å˜æ¢ï¼‰ ----------
    import open3d as o3d

    for tid, data in actor_dict.items():
        if tid not in trajectory:
            continue
        xyz_local = np.concatenate(data['xyz'], axis=0)   # å·²æ˜¯å±€éƒ¨æ¡†
        rgb_local = np.concatenate(data['rgb'], axis=0)
        mask_local = np.concatenate(data['mask'], axis=0)

        # ä»…åšé™é‡‡æ ·ï¼ˆç´¢å¼•æ³•ï¼‰
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(xyz_local)
        pcd.colors = o3d.utility.Vector3dVector(rgb_local / 255.0)
        pcd = pcd.voxel_down_sample(voxel_size=0.15)
        pcd, _ = pcd.remove_radius_outlier(nb_points=10, radius=0.5)

        # æ‹¿ç´¢å¼•å›åŸå§‹æ•°ç»„
        if hasattr(o3d.geometry.PointCloud, 'get_voxel_down_sample_indices'):
            idx = np.asarray(pcd.get_voxel_down_sample_indices())
        else:
            idx = voxel_downsample_indices(xyz_local, 0.15)
        xyz_out = xyz_local[idx]
        rgb_out = rgb_local[idx]
        mask_out = mask_local[idx]

        # å†™å±€éƒ¨æ¡† + mask
        store_ply(os.path.join(out_actor, tid, 'full.ply'), xyz_out, rgb_out, mask_out)
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--seq_dir', required=True, help='path to processed/')
    parser.add_argument('--seq_name', required=True, help='e.g. 000027')
    parser.add_argument('--cams', type=str, default=None,
                        help='è¦å¤„ç†çš„ç›¸æœºï¼Œè‹±æ–‡é€—å·åˆ†éš”ï¼Œå¦‚â€œ0,1,2â€ä»£è¡¨ cam00~cam02ï¼›'
                             'ç•™ç©ºåˆ™é»˜è®¤å¤„ç† 0~6 å…± 7 ä¸ªç›¸æœº')
    args = parser.parse_args()

    ALL_CAMERAS = list(range(7))          # é»˜è®¤ 0~6
    if args.cams is None:
        CAM_IDS = ALL_CAMERAS
    else:
        # å»é‡ + æ’åº + åˆæ³•æ€§æ£€æŸ¥
        try:
            CAM_IDS = sorted({int(c.strip()) for c in args.cams.split(',')})
        except ValueError:
            raise ValueError('--cams å¿…é¡»æ˜¯ç”¨é€—å·åˆ†éš”çš„æ•´æ•°ï¼ˆå¦‚ 0,1,5ï¼‰')
        if not set(CAM_IDS).issubset(ALL_CAMERAS):
            raise ValueError(f'--cams è¶…å‡ºåˆæ³•èŒƒå›´ {ALL_CAMERAS}')
    print('æœ¬æ¬¡å¤„ç†çš„ç›¸æœº IDï¼š', CAM_IDS)
    process(args.seq_dir, args.seq_name,CAM_IDS)

if __name__ == '__main__':
    main()